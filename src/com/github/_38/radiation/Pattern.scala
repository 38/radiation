import com.github._38.radiation.ast._
import com.github._38.radiation.source._
import scala.language.postfixOps
import scala.language.implicitConversions
//TODO get info should generate lexer token based location info
package com.github._38.radiation.pattern {
	/** The conversion helpers */
	object Conversions {
		/** Convert a string to lexer token pattern 
		 *  @note the string has to be a single lexer token
		 */
		implicit def stringToPattern(s:String) = new LexerToken(s)
		/** Convert a signle node to pattern */
		implicit def nodeToPattern(n:Node) = new SignleNode(n)
		/** Convert primitive pattern to compound pattern */
		implicit def primitiveToCompound(p:Primitive) = new Compound(List(p))
		/** Convert list to the pattern list
		 *  @param  l the list to convert
		 *  @param  s the seperator between two nodes
		 *  @return the pattern
		 **/
		def mkList(l:List[Node], s:String = "") = new NodeList(l, s)
		
	}
	
	/** Carries the lexer token position mapping info
	 *  @param source the source file location which contains &lt;line, column, file name &gt; 
	 *  @param target the target file location which only have an offest, because the generated code have only line
	 **/
	case class TokenMapping(val source:KnownLocation, val target:Int, val text:String){
		/** The add operator adds the target location with a base offest */
		def +(base:Int) = TokenMapping(source, target + base, text)
	}
	
	/** Carries the Node offset information in this pattern
	 *  @param  node   the AstNode
	 *  @param  offset the offset in the target code against the beginning of this pattern
	 **/
	case class NodeInfo(val node: Node, val offset:Int){
		def +(base:Int) = NodeInfo(node, offset + base)
	}
	
	/** The base interface for a code pattern */
	trait Pattern{
		import Conversions._
		/** Get the target code */
		def render:String
		/** Get the lexer token mappings */
		def getMappings(sourceLocation:List[Location]):List[TokenMapping] = List()
		/** Get the child node list */
		def getChildren:List[NodeInfo] = List()
		/** The length of the target code */
		def length = render length
		/** Convert this pattern to compund */
		def asCompound = this match {
			case c:Compound => c
			case e:Empty => new Compound(List())
			case p:Primitive => new Compound(List(p))
		}
		/** Concat with another pattern */
		def -- (that: Pattern):Compound = (this,that) match {
			case (l:Empty, r) => r asCompound
			case (l, r:Empty) => l asCompound
			case (l:Compound,r:Compound) => new Compound((l values) ++ (r values))
			case (l:Compound,r:Primitive) => new Compound((l values) ++ (r listify))
			case (l:Primitive, r) => (l:Compound) -- r
		}
	}
	/** Pattern related utils */
	object Pattern {
		/** We need add a white space between two identifers */
		val idEndings = (('a' to 'z') ++ ('A' to 'Z') ++ ('0' to '9') ++ Seq('_', '$')).toSet
		/** Combine a list of string
		 *  @param strs the strings to combine
		 *  @param sep  the seperator
		 */
		def combine(strs:List[String], sep:String) = {
			var result = ""
			var first = true
			for(str <- strs) if(str != "") {
				if(!first) result = result + sep
				result = result + (if(!first && (idEndings contains result.last) && (idEndings contains str.head)) " " + str else str)
				first = false
			}
			result
		}
	}
	/** The pattern that is not Compound */
	trait Primitive extends Pattern{
		/** Make a Primitive a List of one node or List of nothing */
		def listify:List[Primitive];
	}
	/** This is actually an edge in the AST */
	trait Edge extends Primitive;

	/** Contains Lexer Token */
	trait ContainsLexerToken  extends Primitive;
	
	/** Bascially Nothing here */
	class Empty extends Pattern {
		def render = ""
	}
	object Empty {
		val singleton = new Empty;
		def apply() = singleton;
	}
	/** Plain text in the code */
	class LexerToken(text:String) extends Primitive with ContainsLexerToken{
		def render = text;
		override def getMappings(source:List[Location]) = source match {
			case (x:KnownLocation) :: xs => List(TokenMapping(x, 0, text))
			case _       => List()
		}
		def listify = if(text == null) List() else List(this)
	}
	/** Represents a list of node */
	class NodeList(nodes:List[Node], seperator:String) extends Edge with ContainsLexerToken {
		def render = Pattern.combine(nodes map (_ targetCode), seperator)
		override def getChildren = {
			def _scan(todo:List[Node], offset:Int):List[NodeInfo] = todo match {
				case x :: xs => NodeInfo(x, offset) :: _scan(xs, (x length) + offset + (seperator length))
				case _ => List()
			}
			_scan(nodes, 0)
		}
		/** @note The only lexer token generated by Node list is the seperator */
		override def getMappings(source:List[Location]) = 
		{
			def _scan(nodes:List[Node], offset:Int, source:List[Location]):List[TokenMapping] = nodes match {
				case x :: (xs @(y :: xss)) => source match {
					case (s:KnownLocation) :: source => 
						TokenMapping(s ,offset + x.length, seperator) :: _scan(xs, offset + x.length + seperator.length, source)
					case _ :: source =>
						_scan(xs, offset + x.length + seperator.length, source)
					case List()      => List()
				}
				case _ => List()
			}
			_scan(nodes, 0, source)
		}
		
		def listify = if(nodes == null) List() else List(this)
	}
	/** Represents an AST node */
	class SignleNode(node:Node) extends Edge {
		def render = node targetCode
		override def getChildren = List(NodeInfo(node, 0))
		def listify = if(node == null) List() else List(this)
	}
	/** Represents the concats of patterns */
	class Compound(val values:List[Primitive]) extends Pattern {
		def render = Pattern.combine(values map (_ render), "")
		override def getMappings(source:List[Location]) = { 
			def _scan(xs:List[Primitive], source:List[Location], base:Int):List[TokenMapping] = xs match {
				case (x:ContainsLexerToken) :: xs => {
					val head = x.getMappings(source).map(_ + base) 
					val tail = _scan(xs, source drop head.length, base + x.length)
					head ++ tail
				}
				case x :: xs => _scan(xs, source, base + x.length)
				case _ => List()
			}
			val result = _scan(values, source, 0)
			result
		}
		override def getChildren = {
			def _scan(xs:List[Primitive], base:Int):List[NodeInfo] = xs match {
				case x :: xs => x.getChildren.map(_ + base) ++ _scan(xs, base + x.length)
				case _ => List()
			}
			_scan(values, 0)
		}
		override def toString = "Compound" + values
		/** get the index for the first element in the value ist in the location info array 
		 *  @note this is true because we only have two types of instance of ContainsLexerToken 
		          The LexerToken contains exactly one location information 
		          So the index of the first element in the location array should be the same value
		          with the first index in the values array that is a Node List
		*/
		def getListIndex = values.filter(_.isInstanceOf[ContainsLexerToken]).indexWhere(_.isInstanceOf[NodeList]) 
	}
}

// vim: set ts=4 sw=4 et:
